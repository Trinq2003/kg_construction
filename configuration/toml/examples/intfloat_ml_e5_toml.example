[model]
model_name = "intfloat/multilingual-e5-large-instruct"
max_tokens = 8192
embedding_dims = 8192
identical_threshold = 0.9

[path]
local_model = "./model_file/embedding/intfloat_ml_e5" # Local model path
local_tokenizer = "./model_file/embedding/intfloat_ml_e5" # Local tokenizer path
local_config = "" # Local config path
local_cache = "" # Local cache path

[deployment]
device = "cuda:6"  # Device to deploy the model (e.g., "cuda", "cpu")
tensor_parallel_size = 2  # Number of GPUs for tensor parallelism
gpu_memory_utilization = 0.9  # GPU memory utilization
dtype = "auto"  # Data type for model weights (e.g., "auto", "float16")